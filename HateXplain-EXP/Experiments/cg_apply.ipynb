{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c03e2b6-0e4d-4837-8abf-b8400a8d50a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from concept_gradient_v2 import ConceptGradients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a6c7ee16-0ab5-429d-ae4e-4518c83adf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "from tqdm.auto import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from datasets import Dataset\n",
    "from concept_gradient_v2 import ConceptGradients\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "48f599fd-2145-44c6-a65b-1acaf8576058",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "class X2YModel(nn.Module):\n",
    "    def __init__(self, model_name='./target_model_he/checkpoint-150', num_classes=2):\n",
    "        super(X2YModel, self).__init__()\n",
    "        self.model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_classes)\n",
    "        \n",
    "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
    "        if inputs_embeds is not None:\n",
    "            outputs = self.model.roberta(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
    "        else:\n",
    "            outputs = self.model.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.model.classifier(outputs.last_hidden_state)  \n",
    "\n",
    "\n",
    "class X2CModel(nn.Module):\n",
    "    def __init__(self, model_name='./concept_model_he/checkpoint-1900', num_concepts=3):\n",
    "        super(X2CModel, self).__init__()\n",
    "        self.model = RobertaForSequenceClassification.from_pretrained(model_name, num_labels=num_concepts, ignore_mismatched_sizes=True).to('cuda')\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, inputs_embeds=None):\n",
    "        if inputs_embeds is not None:\n",
    "            outputs = self.model.roberta(inputs_embeds=inputs_embeds, attention_mask=attention_mask)\n",
    "        else:\n",
    "            outputs = self.model.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        return self.model.classifier(outputs.last_hidden_state)\n",
    "\n",
    "x2y_model = X2YModel().to(device)\n",
    "x2c_model = X2CModel().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9338044a-ee84-4261-97f4-823e6eba33dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_func(embeddings, attention_mask):\n",
    "    output = x2y_model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "    return output\n",
    "\n",
    "def concept_forward_func(embeddings, attention_mask):\n",
    "    output = x2c_model(inputs_embeds=embeddings, attention_mask=attention_mask)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9f4eab0e-4ea2-4682-b0b5-4a74862effe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cg = ConceptGradients(forward_func, concept_forward_func=concept_forward_func, x2y_model=x2y_model, x2c_model=x2c_model)\n",
    "\n",
    "def calculate_concept_gradient(input_ids, attention_mask, target_index, concept_index, mode):\n",
    "    input_ids = input_ids.to(device)\n",
    "    attention_mask = attention_mask.to(device)  \n",
    "\n",
    "    with torch.no_grad():\n",
    "        embeddings = x2y_model.model.get_input_embeddings()(input_ids)\n",
    "        \n",
    "    embeddings.requires_grad_(True)\n",
    "    attention_mask = attention_mask.float()\n",
    "    attention_mask.requires_grad_(True)\n",
    "    attr = cg.attribute(\n",
    "        (embeddings, attention_mask),\n",
    "        mode=mode,\n",
    "        target=target_index,\n",
    "        target_concept=concept_index,\n",
    "        n_concepts=3,\n",
    "        target_layer_name='roberta.encoder.layer.11.output.dense',\n",
    "        concept_layer_name='roberta.encoder.layer.11.output.dense',\n",
    "    )\n",
    "\n",
    "    return attr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99b741a0-75e4-44a7-922f-46144c60f7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('../data/hatexplain_test.csv')\n",
    "df_test = df_test.drop(columns=['post_id', 'Miscellaneous', 'Sexual Orientation'])\n",
    "# df_test = df_test.sample(1500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "876dbf4b-8d0d-4547-942c-e1f703cfe542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['concept_labels'] = df_test[['Race', \"Religion\", 'Gender']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "69037e78-12a2-4a62-9790-af3a63041a1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>label</th>\n",
       "      <th>Race</th>\n",
       "      <th>Religion</th>\n",
       "      <th>Gender</th>\n",
       "      <th>concept_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>699</th>\n",
       "      <td>you niggas faggots putting you all hands on fe...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>as for jews revenge is the only answer i blame...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>the reply i and everyone else who complained g...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>different caliber rifles being fired shoddy ai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>idiot boy trudeau his somali moslem immigratio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>grown ass men doing women activities and lil f...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>brits you should maybe storm the prison britai...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 1.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>whoopi goldberk aka caryn johnson is a stupid ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[1.0, 0.0, 1.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>837</th>\n",
       "      <td>&lt;user&gt; said nazis look cool pretty much</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the labour party has &lt;number&gt; mps in prison fo...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              post_text  label  Race  \\\n",
       "699   you niggas faggots putting you all hands on fe...    1.0   1.0   \n",
       "1121  as for jews revenge is the only answer i blame...    1.0   0.0   \n",
       "294   the reply i and everyone else who complained g...    0.0   0.0   \n",
       "318   different caliber rifles being fired shoddy ai...    1.0   1.0   \n",
       "35    idiot boy trudeau his somali moslem immigratio...    1.0   1.0   \n",
       "48    grown ass men doing women activities and lil f...    1.0   0.0   \n",
       "687   brits you should maybe storm the prison britai...    1.0   1.0   \n",
       "1024  whoopi goldberk aka caryn johnson is a stupid ...    1.0   1.0   \n",
       "837             <user> said nazis look cool pretty much    0.0   1.0   \n",
       "8     the labour party has <number> mps in prison fo...    1.0   0.0   \n",
       "\n",
       "      Religion  Gender   concept_labels  \n",
       "699        0.0     0.0  [1.0, 0.0, 0.0]  \n",
       "1121       1.0     0.0  [0.0, 1.0, 0.0]  \n",
       "294        0.0     0.0  [0.0, 0.0, 0.0]  \n",
       "318        0.0     0.0  [1.0, 0.0, 0.0]  \n",
       "35         1.0     0.0  [1.0, 1.0, 0.0]  \n",
       "48         0.0     0.0  [0.0, 0.0, 0.0]  \n",
       "687        1.0     1.0  [1.0, 1.0, 1.0]  \n",
       "1024       0.0     1.0  [1.0, 0.0, 1.0]  \n",
       "837        1.0     0.0  [1.0, 1.0, 0.0]  \n",
       "8          1.0     0.0  [0.0, 1.0, 0.0]  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a85f6f1d-de9d-4821-a315-a0c83cd9c46a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>post_text</th>\n",
       "      <th>label</th>\n",
       "      <th>concept_labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i dont think im getting my baby them white 9 h...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>laura loomer raped me while screaming at me in...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>[0.0, 1.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;user&gt; what did the old lady do was she a nazi...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>as much as i appreciate a format of open discu...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[1.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; with a room full of white...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>[0.0, 0.0, 0.0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           post_text  label   concept_labels\n",
       "0  i dont think im getting my baby them white 9 h...    0.0  [0.0, 0.0, 0.0]\n",
       "1  laura loomer raped me while screaming at me in...    1.0  [0.0, 1.0, 0.0]\n",
       "2  <user> what did the old lady do was she a nazi...    0.0  [0.0, 0.0, 0.0]\n",
       "3  as much as i appreciate a format of open discu...    0.0  [1.0, 0.0, 0.0]\n",
       "4  <user> <user> <user> with a room full of white...    0.0  [0.0, 0.0, 0.0]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_test.drop(columns=['Race', 'Religion', 'Gender'], inplace=True, axis=1)\n",
    "ds_test = Dataset.from_pandas(df_test)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "03dfdcc9-ef5c-4f5d-b0db-a2a4b85f8014",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/2017025/sgarg01/.python3-3.12-torch220/site-packages/lib/python3.12/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46a32125c67e4a089e3c559b8a2a197b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1186 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"post_text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "tokenized_dataset = ds_test.map(tokenize_function, batched=True)\n",
    "tokenized_dataset.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"concept_labels\", \"label\"])\n",
    "\n",
    "x2y_dl_test = DataLoader(tokenized_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d3a1c2ba-d767-4b4c-942f-82052acee691",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3145f4e406a402a8a3091f7833130e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/149 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process complete. Results saved to 'misclassified_samples_with_concept_gradients.csv'\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "x2y_dl_test = DataLoader(tokenized_dataset, batch_size=8, shuffle=False)\n",
    "for batch in tqdm(x2y_dl_test, leave=True):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['label'].long().to(device)\n",
    "    concept_labels = batch['concept_labels']\n",
    "\n",
    "    target_logits = x2y_model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "    target_preds = torch.argmax(target_logits, dim=-1)\n",
    "\n",
    "    incorrect_indices = (target_preds == labels).nonzero(as_tuple=True)[0]\n",
    "\n",
    "    if len(incorrect_indices) > 0:\n",
    "        for idx in incorrect_indices:\n",
    "            sample_input_ids = input_ids[idx].unsqueeze(0)\n",
    "            sample_attention_mask = attention_mask[idx].unsqueeze(0)\n",
    "            sample_label = int(labels[idx].item())\n",
    "            sample_concept_label = concept_labels[idx].unsqueeze(0)\n",
    "            sample_sentence = tokenizer.decode(sample_input_ids.squeeze(), skip_special_tokens=True)\n",
    "\n",
    "            concept_gradient = calculate_concept_gradient(sample_input_ids, sample_attention_mask, target_index=sample_label, concept_index=None, mode='chain_rule_independent')\n",
    "            concept_gradient = concept_gradient[0].detach().cpu().numpy()\n",
    "\n",
    "            concept_logits = x2c_model(input_ids=sample_input_ids, attention_mask=sample_attention_mask)\n",
    "            concept_logits = torch.sigmoid(concept_logits).detach().cpu().numpy()\n",
    "\n",
    "            target_logits_final = x2y_model(input_ids=sample_input_ids, attention_mask=sample_attention_mask)\n",
    "            target_logits_final = torch.softmax(target_logits_final, dim=-1).detach().cpu().numpy()\n",
    "\n",
    "            results.append({\n",
    "                \"sentence\": sample_sentence,\n",
    "                \"target_logits\": target_logits_final,\n",
    "                \"concept_logits\": concept_logits,\n",
    "                \"concept_gradient\": concept_gradient,\n",
    "                \"label\": sample_label,\n",
    "                \"concept_label\": sample_concept_label.cpu().numpy()  \n",
    "            })\n",
    "            \n",
    "df_results = pd.DataFrame(results)\n",
    "df_results.to_csv(\"misclassified_samples/cs_cg.csv\", index=False)\n",
    "\n",
    "print(\"Process complete. Results saved to 'misclassified_samples_with_concept_gradients.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0c7fe46e-9d4d-410c-8ce3-ecee03cd4f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>target_logits</th>\n",
       "      <th>concept_logits</th>\n",
       "      <th>concept_gradient</th>\n",
       "      <th>label</th>\n",
       "      <th>concept_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>fun fact did you know kardashian is armenian for nigger lover</td>\n",
       "      <td>[[0.005222132, 0.9947779]]</td>\n",
       "      <td>[[0.9441051, 0.41052046, 0.060839996]]</td>\n",
       "      <td>[[0.057885244, 0.18912065, -0.017316096]]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.0, 0.0, 0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>does anyone get the feeling that nick the spic fuentes is like trying to court &lt;number&gt; something internet savvy boomer conservatives as if they were a thing</td>\n",
       "      <td>[[0.012301511, 0.98769844]]</td>\n",
       "      <td>[[0.52831227, 0.5304703, 0.12408364]]</td>\n",
       "      <td>[[0.014800973, 0.16851409, -0.0020840436]]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[1.0, 0.0, 0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>356</th>\n",
       "      <td>knock off a cracker for callin me towelhead</td>\n",
       "      <td>[[0.19415505, 0.8058449]]</td>\n",
       "      <td>[[0.56199807, 0.012359233, 0.49713323]]</td>\n",
       "      <td>[[0.007912772, 0.25178832, 0.009786654]]</td>\n",
       "      <td>1</td>\n",
       "      <td>[[0.0, 0.0, 0.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>&lt;user&gt; &lt;user&gt; &lt;user&gt; millions of yemeni children starve because of trump policies republicans i sleep a woman gets raped and does not want to carry his baby republicans real shit</td>\n",
       "      <td>[[0.9601562, 0.03984379]]</td>\n",
       "      <td>[[0.03316694, 0.039621964, 0.37312835]]</td>\n",
       "      <td>[[0.19554447, -0.074995644, -0.023832707]]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[0.0, 0.0, 1.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>gta san andreas the story of an above average somewhat talented black man who escapes the ghetto and becomes reasonably successful only to be dragged back in in the final act because his brother is a stubborn dumbass -_-</td>\n",
       "      <td>[[0.96210974, 0.03789029]]</td>\n",
       "      <td>[[0.5966021, 0.0057812273, 0.37690967]]</td>\n",
       "      <td>[[0.2581864, -0.15948421, -0.054642722]]</td>\n",
       "      <td>0</td>\n",
       "      <td>[[1.0, 0.0, 0.0]]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                          sentence  \\\n",
       "358                                                                                                                                                                  fun fact did you know kardashian is armenian for nigger lover   \n",
       "140                                                                  does anyone get the feeling that nick the spic fuentes is like trying to court <number> something internet savvy boomer conservatives as if they were a thing   \n",
       "356                                                                                                                                                                                    knock off a cracker for callin me towelhead   \n",
       "21                                              <user> <user> <user> millions of yemeni children starve because of trump policies republicans i sleep a woman gets raped and does not want to carry his baby republicans real shit   \n",
       "1034  gta san andreas the story of an above average somewhat talented black man who escapes the ghetto and becomes reasonably successful only to be dragged back in in the final act because his brother is a stubborn dumbass -_-   \n",
       "\n",
       "                    target_logits                           concept_logits  \\\n",
       "358    [[0.005222132, 0.9947779]]   [[0.9441051, 0.41052046, 0.060839996]]   \n",
       "140   [[0.012301511, 0.98769844]]    [[0.52831227, 0.5304703, 0.12408364]]   \n",
       "356     [[0.19415505, 0.8058449]]  [[0.56199807, 0.012359233, 0.49713323]]   \n",
       "21      [[0.9601562, 0.03984379]]  [[0.03316694, 0.039621964, 0.37312835]]   \n",
       "1034   [[0.96210974, 0.03789029]]  [[0.5966021, 0.0057812273, 0.37690967]]   \n",
       "\n",
       "                                concept_gradient  label      concept_label  \n",
       "358    [[0.057885244, 0.18912065, -0.017316096]]      1  [[1.0, 0.0, 0.0]]  \n",
       "140   [[0.014800973, 0.16851409, -0.0020840436]]      1  [[1.0, 0.0, 0.0]]  \n",
       "356     [[0.007912772, 0.25178832, 0.009786654]]      1  [[0.0, 0.0, 0.0]]  \n",
       "21    [[0.19554447, -0.074995644, -0.023832707]]      0  [[0.0, 0.0, 1.0]]  \n",
       "1034    [[0.2581864, -0.15948421, -0.054642722]]      0  [[1.0, 0.0, 0.0]]  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "df_results.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af6d5ce5-f693-4d35-a604-ac006b3dc91e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(232, 6)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1787b75-b44d-4879-b37e-8aaf65442f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1250/1250 [02:29<00:00,  8.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 1 Accuracy: 0.8894\n",
      "Concept 2 Accuracy: 0.8424\n",
      "Concept 3 Accuracy: 0.7192\n",
      "Concept 4 Accuracy: 0.9420\n",
      "Concept 5 Accuracy: 0.7536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Initialize lists to store predictions and true labels for each concept\n",
    "concept_predictions = [[] for _ in range(5)]\n",
    "concept_true_labels = [[] for _ in range(5)]\n",
    "\n",
    "for batch in tqdm(x2y_dl_test, leave=True):\n",
    "    input_ids = batch['input_ids'].to(device)\n",
    "    attention_mask = batch['attention_mask'].to(device)\n",
    "    labels = batch['toxicity'].to(device)\n",
    "    concept_labels = batch['concept_labels'].to(device)\n",
    "    \n",
    "    # Compute logits for concept model\n",
    "    concept_logits = x2c_model(input_ids, attention_mask=attention_mask)\n",
    "    \n",
    "    # Apply sigmoid to get probabilities\n",
    "    concept_probs = torch.sigmoid(concept_logits)\n",
    "    \n",
    "    # Convert probabilities to binary predictions (0 or 1)\n",
    "    concept_preds = (concept_probs > 0.5).int()\n",
    "    \n",
    "    # Store predictions and true labels for each concept\n",
    "    for i in range(5):\n",
    "        concept_predictions[i].extend(concept_preds[:, i].cpu().numpy())\n",
    "        concept_true_labels[i].extend(concept_labels[:, i].cpu().numpy())\n",
    "\n",
    "# Compute accuracy for each concept\n",
    "concept_accuracies = []\n",
    "for i in range(5):\n",
    "    accuracy = accuracy_score(concept_true_labels[i], concept_predictions[i])\n",
    "    concept_accuracies.append(accuracy)\n",
    "\n",
    "# Print accuracies for each concept\n",
    "for i, accuracy in enumerate(concept_accuracies):\n",
    "    print(f\"Concept {i+1} Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b71f0ce0-03a2-49e5-b326-0f0d0104e305",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept 1 F1: 0.8395\n",
      "Concept 2 F1: 0.3226\n",
      "Concept 3 F1: 0.3728\n",
      "Concept 4 F1: 0.9240\n",
      "Concept 5 F1: 0.3827\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "concept_f1 = []\n",
    "for i in range(5):\n",
    "    accuracy = f1_score(concept_true_labels[i], concept_predictions[i])\n",
    "    concept_f1.append(accuracy)\n",
    "\n",
    "# Print accuracies for each concept\n",
    "for i, accuracy in enumerate(concept_f1):\n",
    "    print(f\"Concept {i+1} F1: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch 2.2.0",
   "language": "python",
   "name": "torch220"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
